{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package abc to\n",
      "[nltk_data]     C:\\Users\\steli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package abc is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\steli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from language_model import LM\n",
    "import nltk.corpus\n",
    "nltk.download('abc')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "766811"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = nltk.corpus.abc.sents()\n",
    "len([word for sent in sentences for word in sent])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to create an instance of the model. if n_type is equal to 'bigram', then an instance of a bigram model is created. If n_type is set to trigram, then a 'trigram' model is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_model = LM(n_type='bigram')\n",
    "tri_model = LM(n_type='trigram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have to train the model. The input must be a list of lists, where each list is a sentence. All the cleaning and padding is handled by the model, so we just have to feed it with raw sentences (for example, for the bigram model, if we pass to the train method the sentence ['ThI,!s', 'iS', '.A.', 'tE==++sT'], the model will transform the sentence to ['* start *', 'this', 'is', 'a', 'test', '* end *'] and it will create all the necessary vocabularies.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained, then the following methods can be called:\n",
    "Let b_model be an instance of a bigram model:\n",
    " - b_model.unigram_voc_ -> this will return the vocabulary of all unigrams\n",
    " - b_model.bigram_voc_ -> this will return the vocabulary of all bigrams (for the trigram model we would have to make an instance of a trigram model using LM(n_type='trigram'))\n",
    " - b_model.add_a_prob() -> this will calculate the probability of a given bigram (or trigram if we use the trigram model) using Add-a smoothing, where the hyper-parameter 'a' can be tuned in order to achieve the lowest possible Cross-Entropy\n",
    " - b_model.kn_prob() -> this will calculate the probability of a given bigram using the interpolated Kneser-Ney smoothing, where the constant D is equal to 0.5 for bigrams with a count of 1 and 0.75 for the rest.\n",
    " - b_model.estimate_sent_prob() -> this will calculate the log probabilities of all the given sentences. If more than one sentence is given as an input, then it will return a list with the probabilities of each sentence (which could then be summed and thus, calculate the total log probability of ,eg, the test corpus). There are two available smoothers for bigrams. Add-a smoothing and Interpolated Kneser-Ney smoothing.\n",
    " - b_model.entr_perp() -> this will return the Cross-Entropy and Perplexity of the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some other static methods can be called (they don't require an instance creation):\n",
    " - Model.word_cleaner() -> this will clean any list of words. It will remove any character that is not a letter or number, and it will apply lower case to all the words\n",
    " - Model.sent_preprocessing() -> this will clean and pad any sentence that is given as an input\n",
    " - Model.bigram() -> this will create bigrams of a given sentence\n",
    " - Model.trigram() -> this will create trigrams of a given sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_model.train(sentences)  # train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating the probability of a bigram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add-a smoothing (with a=1) probability: 0.04117362955807776\n",
      "K-N probability: 0.12414558851175722\n"
     ]
    }
   ],
   "source": [
    "laplace = bi_model.add_a_prob(('this', 'is'))\n",
    "kn = bi_model.kn_prob(('this', 'is'))\n",
    "print(f\"Add-a smoothing (with a=1) probability: {laplace}\\nK-N probability: {kn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating the log probability of a sentence using laplace smoothing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-34.326750073789114]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_model.estimate_sent_prob([['this', 'is', 'a', 'test']], smoothing='add_a')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating the log probability of a sentence using the Interpolated Kneser-Ney smoother:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-26.54752395643943]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_model.estimate_sent_prob([['this', 'is', 'a', 'test']], smoothing='kn')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the bigram vocabulary attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('*start*', 'pm'): 9,\n",
       "         ('pm', 'denies'): 1,\n",
       "         ('denies', 'knowledge'): 1,\n",
       "         ('knowledge', 'of'): 18,\n",
       "         ('of', 'awb'): 36,\n",
       "         ('awb', 'kickbacks'): 5,\n",
       "         ('kickbacks', 'the'): 1,\n",
       "         ('the', 'prime'): 40,\n",
       "         ('prime', 'minister'): 91,\n",
       "         ('minister', 'has'): 5,\n",
       "         ('has', 'denied'): 7,\n",
       "         ('denied', 'he'): 2,\n",
       "         ('he', 'knew'): 4,\n",
       "         ('knew', 'awb'): 2,\n",
       "         ('awb', 'was'): 9,\n",
       "         ('was', 'paying'): 3,\n",
       "         ('paying', 'kickbacks'): 2,\n",
       "         ('kickbacks', 'to'): 12,\n",
       "         ('to', 'iraq'): 32,\n",
       "         ('iraq', 'despite'): 1,\n",
       "         ('despite', 'writing'): 1,\n",
       "         ('writing', 'to'): 2,\n",
       "         ('to', 'the'): 1469,\n",
       "         ('the', 'wheat'): 75,\n",
       "         ('wheat', 'exporter'): 49,\n",
       "         ('exporter', 'asking'): 1,\n",
       "         ('asking', 'to'): 1,\n",
       "         ('to', 'be'): 1215,\n",
       "         ('be', 'kept'): 7,\n",
       "         ('kept', 'fully'): 1,\n",
       "         ('fully', 'informed'): 1,\n",
       "         ('informed', 'on'): 1,\n",
       "         ('on', 'iraq'): 4,\n",
       "         ('iraq', 'wheat'): 11,\n",
       "         ('wheat', 'sales'): 8,\n",
       "         ('sales', '*end*'): 15,\n",
       "         ('*start*', 'letters'): 1,\n",
       "         ('letters', 'from'): 1,\n",
       "         ('from', 'john'): 2,\n",
       "         ('john', 'howard'): 35,\n",
       "         ('howard', 'and'): 3,\n",
       "         ('and', 'deputy'): 3,\n",
       "         ('deputy', 'prime'): 22,\n",
       "         ('minister', 'mark'): 24,\n",
       "         ('mark', 'vaile'): 37,\n",
       "         ('vaile', 'to'): 2,\n",
       "         ('to', 'awb'): 9,\n",
       "         ('awb', 'have'): 3,\n",
       "         ('have', 'been'): 747,\n",
       "         ('been', 'released'): 9,\n",
       "         ('released', 'by'): 12,\n",
       "         ('by', 'the'): 607,\n",
       "         ('the', 'cole'): 85,\n",
       "         ('cole', 'inquiry'): 88,\n",
       "         ('inquiry', 'into'): 31,\n",
       "         ('into', 'the'): 372,\n",
       "         ('the', 'oil'): 84,\n",
       "         ('oil', 'for'): 77,\n",
       "         ('for', 'food'): 98,\n",
       "         ('food', 'program'): 17,\n",
       "         ('program', '*end*'): 34,\n",
       "         ('*start*', 'in'): 579,\n",
       "         ('in', 'one'): 56,\n",
       "         ('one', 'of'): 452,\n",
       "         ('of', 'the'): 4666,\n",
       "         ('the', 'letters'): 3,\n",
       "         ('letters', 'mr'): 1,\n",
       "         ('mr', 'howard'): 19,\n",
       "         ('howard', 'asks'): 1,\n",
       "         ('asks', 'awb'): 1,\n",
       "         ('awb', 'managing'): 3,\n",
       "         ('managing', 'director'): 63,\n",
       "         ('director', 'andrew'): 9,\n",
       "         ('andrew', 'lindberg'): 12,\n",
       "         ('lindberg', 'to'): 1,\n",
       "         ('to', 'remain'): 12,\n",
       "         ('remain', 'in'): 8,\n",
       "         ('in', 'close'): 3,\n",
       "         ('close', 'contact'): 4,\n",
       "         ('contact', 'with'): 24,\n",
       "         ('with', 'the'): 740,\n",
       "         ('the', 'government'): 236,\n",
       "         ('government', 'on'): 6,\n",
       "         ('*start*', 'the'): 4603,\n",
       "         ('the', 'opposition'): 15,\n",
       "         ('opposition', '*UNK*'): 7,\n",
       "         ('*UNK*', '*UNK*'): 8488,\n",
       "         ('*UNK*', 'connor'): 27,\n",
       "         ('connor', 'says'): 10,\n",
       "         ('says', 'the'): 1301,\n",
       "         ('the', 'letter'): 3,\n",
       "         ('letter', 'was'): 1,\n",
       "         ('was', 'sent'): 4,\n",
       "         ('sent', 'in'): 2,\n",
       "         ('in', '2002'): 19,\n",
       "         ('2002', 'the'): 4,\n",
       "         ('the', 'same'): 338,\n",
       "         ('same', 'time'): 37,\n",
       "         ('time', 'awb'): 1,\n",
       "         ('iraq', 'though'): 1,\n",
       "         ('though', 'a'): 4,\n",
       "         ('a', '*UNK*'): 2148,\n",
       "         ('*UNK*', 'trucking'): 4,\n",
       "         ('trucking', 'company'): 6,\n",
       "         ('company', '*end*'): 28,\n",
       "         ('*start*', 'he'): 697,\n",
       "         ('he', 'says'): 1358,\n",
       "         ('government', 'can'): 7,\n",
       "         ('can', 'longer'): 1,\n",
       "         ('longer', '*UNK*'): 19,\n",
       "         ('*UNK*', 'its'): 109,\n",
       "         ('its', 'hands'): 1,\n",
       "         ('hands', 'of'): 5,\n",
       "         ('the', '*UNK*'): 5191,\n",
       "         ('*UNK*', 'payments'): 11,\n",
       "         ('payments', 'which'): 1,\n",
       "         ('which', '*UNK*'): 136,\n",
       "         ('*UNK*', 'million'): 363,\n",
       "         ('million', '*end*'): 53,\n",
       "         ('the', 'responsibility'): 3,\n",
       "         ('responsibility', 'for'): 13,\n",
       "         ('for', 'this'): 55,\n",
       "         ('this', 'must'): 1,\n",
       "         ('must', 'lay'): 1,\n",
       "         ('lay', 'may'): 1,\n",
       "         ('may', '*UNK*'): 39,\n",
       "         ('*UNK*', 'at'): 439,\n",
       "         ('at', 'the'): 1248,\n",
       "         ('the', 'feet'): 4,\n",
       "         ('feet', 'of'): 1,\n",
       "         ('of', 'coalition'): 2,\n",
       "         ('coalition', 'ministers'): 1,\n",
       "         ('ministers', 'in'): 1,\n",
       "         ('in', 'trade'): 4,\n",
       "         ('trade', 'agriculture'): 1,\n",
       "         ('agriculture', 'and'): 47,\n",
       "         ('and', 'the'): 972,\n",
       "         ('minister', 'he'): 2,\n",
       "         ('he', 'said'): 1588,\n",
       "         ('said', '*end*'): 1982,\n",
       "         ('*start*', 'but'): 1381,\n",
       "         ('but', 'the'): 310,\n",
       "         ('minister', 'says'): 14,\n",
       "         ('says', 'letters'): 1,\n",
       "         ('letters', 'show'): 1,\n",
       "         ('show', 'he'): 1,\n",
       "         ('he', 'was'): 57,\n",
       "         ('was', '*UNK*'): 252,\n",
       "         ('*UNK*', 'about'): 177,\n",
       "         ('about', 'the'): 304,\n",
       "         ('the', 'future'): 164,\n",
       "         ('future', 'of'): 69,\n",
       "         ('of', 'wheat'): 60,\n",
       "         ('sales', 'in'): 11,\n",
       "         ('in', 'iraq'): 10,\n",
       "         ('iraq', 'and'): 6,\n",
       "         ('and', 'do'): 19,\n",
       "         ('do', 'not'): 99,\n",
       "         ('not', 'prove'): 3,\n",
       "         ('prove', 'the'): 5,\n",
       "         ('government', 'knew'): 1,\n",
       "         ('knew', 'of'): 2,\n",
       "         ('the', 'payments'): 7,\n",
       "         ('payments', '*end*'): 6,\n",
       "         ('*start*', 'it'): 1156,\n",
       "         ('it', 'would'): 136,\n",
       "         ('would', 'have'): 192,\n",
       "         ('been', '*UNK*'): 307,\n",
       "         ('*UNK*', 'in'): 1873,\n",
       "         ('2002', 'if'): 1,\n",
       "         ('if', 'as'): 3,\n",
       "         ('as', 'prime'): 1,\n",
       "         ('minister', 'i'): 1,\n",
       "         ('i', '*UNK*'): 173,\n",
       "         ('*UNK*', 'done'): 7,\n",
       "         ('done', 'anything'): 3,\n",
       "         ('anything', 'i'): 1,\n",
       "         ('i', 'possibly'): 1,\n",
       "         ('possibly', 'could'): 1,\n",
       "         ('could', 'to'): 2,\n",
       "         ('to', 'preserve'): 15,\n",
       "         ('preserve', 'australia'): 1,\n",
       "         ('australia', '*UNK*'): 582,\n",
       "         ('*UNK*', 'very'): 62,\n",
       "         ('very', 'valuable'): 1,\n",
       "         ('valuable', 'wheat'): 1,\n",
       "         ('wheat', 'market'): 9,\n",
       "         ('market', 'he'): 21,\n",
       "         ('*start*', 'email'): 1,\n",
       "         ('email', 'questions'): 1,\n",
       "         ('questions', 'today'): 1,\n",
       "         ('today', 'at'): 6,\n",
       "         ('the', 'inquiry'): 43,\n",
       "         ('inquiry', 'awb'): 3,\n",
       "         ('awb', 'trading'): 1,\n",
       "         ('trading', 'manager'): 1,\n",
       "         ('manager', 'peter'): 3,\n",
       "         ('peter', '*UNK*'): 120,\n",
       "         ('*UNK*', 'has'): 395,\n",
       "         ('has', 'been'): 837,\n",
       "         ('been', 'questioned'): 2,\n",
       "         ('questioned', 'about'): 2,\n",
       "         ('about', 'an'): 6,\n",
       "         ('an', 'email'): 5,\n",
       "         ('email', 'he'): 1,\n",
       "         ('he', 'received'): 6,\n",
       "         ('received', 'in'): 2,\n",
       "         ('in', 'may'): 11,\n",
       "         ('may', '2000'): 1,\n",
       "         ('2000', '*end*'): 7,\n",
       "         ('it', '*UNK*'): 1277,\n",
       "         ('*UNK*', 'that'): 737,\n",
       "         ('that', 'the'): 665,\n",
       "         ('the', 'iraqi'): 24,\n",
       "         ('iraqi', 'grains'): 11,\n",
       "         ('grains', 'board'): 12,\n",
       "         ('board', 'had'): 1,\n",
       "         ('had', '*UNK*'): 79,\n",
       "         ('*UNK*', 'awb'): 27,\n",
       "         ('awb', 'to'): 20,\n",
       "         ('to', 'provide'): 67,\n",
       "         ('provide', 'after'): 1,\n",
       "         ('after', 'sales'): 3,\n",
       "         ('sales', 'service'): 3,\n",
       "         ('service', '*end*'): 12,\n",
       "         ('*start*', 'mr'): 181,\n",
       "         ('mr', '*UNK*'): 203,\n",
       "         ('*UNK*', 'said'): 150,\n",
       "         ('said', 'he'): 15,\n",
       "         ('he', 'had'): 32,\n",
       "         ('*UNK*', 'the'): 2046,\n",
       "         ('the', 'email'): 9,\n",
       "         ('email', 'to'): 3,\n",
       "         ('to', 'two'): 16,\n",
       "         ('two', 'awb'): 1,\n",
       "         ('awb', 'colleagues'): 1,\n",
       "         ('colleagues', 'and'): 4,\n",
       "         ('and', 'did'): 9,\n",
       "         ('did', 'not'): 129,\n",
       "         ('not', 'remember'): 1,\n",
       "         ('remember', 'reading'): 1,\n",
       "         ('reading', 'it'): 1,\n",
       "         ('it', 'although'): 1,\n",
       "         ('although', 'he'): 6,\n",
       "         ('he', 'may'): 4,\n",
       "         ('may', 'have'): 157,\n",
       "         ('have', '*UNK*'): 340,\n",
       "         ('*UNK*', 'it'): 288,\n",
       "         ('it', '*end*'): 169,\n",
       "         ('*start*', 'support'): 1,\n",
       "         ('support', 'awb'): 2,\n",
       "         ('awb', 'still'): 5,\n",
       "         ('still', 'has'): 8,\n",
       "         ('has', 'plenty'): 1,\n",
       "         ('plenty', 'of'): 22,\n",
       "         ('of', 'support'): 7,\n",
       "         ('support', 'among'): 1,\n",
       "         ('among', 'grain'): 1,\n",
       "         ('grain', 'growers'): 69,\n",
       "         ('growers', 'in'): 64,\n",
       "         ('in', 'central'): 56,\n",
       "         ('central', 'western'): 15,\n",
       "         ('western', 'new'): 36,\n",
       "         ('new', 'south'): 421,\n",
       "         ('south', 'wales'): 421,\n",
       "         ('wales', 'despite'): 1,\n",
       "         ('despite', 'the'): 44,\n",
       "         ('*UNK*', 'of'): 2353,\n",
       "         ('inquiry', '*end*'): 43,\n",
       "         ('*start*', 'producers'): 10,\n",
       "         ('producers', 'say'): 4,\n",
       "         ('say', 'they'): 144,\n",
       "         ('they', '*UNK*'): 160,\n",
       "         ('*UNK*', 'support'): 15,\n",
       "         ('awb', '*UNK*'): 126,\n",
       "         ('*UNK*', 'attempts'): 4,\n",
       "         ('attempts', 'to'): 20,\n",
       "         ('to', 'get'): 288,\n",
       "         ('get', 'the'): 62,\n",
       "         ('the', 'best'): 125,\n",
       "         ('best', 'prices'): 2,\n",
       "         ('prices', 'for'): 36,\n",
       "         ('for', 'their'): 87,\n",
       "         ('their', 'products'): 6,\n",
       "         ('products', '*end*'): 15,\n",
       "         ('*start*', 'i'): 540,\n",
       "         ('i', 'think'): 323,\n",
       "         ('think', 'it'): 88,\n",
       "         ('*UNK*', 'all'): 69,\n",
       "         ('all', 'a'): 2,\n",
       "         ('*UNK*', 'by'): 511,\n",
       "         ('by', 'overseas'): 2,\n",
       "         ('overseas', 'interests'): 1,\n",
       "         ('interests', 'to'): 1,\n",
       "         ('to', 'try'): 103,\n",
       "         ('try', 'and'): 30,\n",
       "         ('and', 'get'): 25,\n",
       "         ('the', 'single'): 106,\n",
       "         ('single', 'desk'): 141,\n",
       "         ('desk', 'put'): 1,\n",
       "         ('put', 'aside'): 2,\n",
       "         ('aside', '*end*'): 1,\n",
       "         ('the', 'stories'): 2,\n",
       "         ('stories', 'that'): 2,\n",
       "         ('that', 'are'): 201,\n",
       "         ('are', 'going'): 64,\n",
       "         ('going', 'round'): 1,\n",
       "         ('round', 'about'): 1,\n",
       "         ('the', 'commission'): 21,\n",
       "         ('commission', 'and'): 3,\n",
       "         ('and', 'everything'): 7,\n",
       "         ('everything', 'i'): 1,\n",
       "         ('think', 'that'): 89,\n",
       "         ('that', '*UNK*'): 921,\n",
       "         ('the', 'way'): 144,\n",
       "         ('way', 'people'): 4,\n",
       "         ('people', 'have'): 67,\n",
       "         ('have', 'got'): 56,\n",
       "         ('got', 'to'): 61,\n",
       "         ('to', 'do'): 208,\n",
       "         ('do', 'things'): 3,\n",
       "         ('things', 'to'): 8,\n",
       "         ('do', 'business'): 5,\n",
       "         ('business', 'with'): 5,\n",
       "         ('the', 'middle'): 73,\n",
       "         ('middle', 'east'): 37,\n",
       "         ('east', 'and'): 8,\n",
       "         ('and', 'asian'): 1,\n",
       "         ('asian', 'countries'): 2,\n",
       "         ('countries', 'one'): 1,\n",
       "         ('one', 'producer'): 3,\n",
       "         ('producer', 'said'): 4,\n",
       "         ('*UNK*', 'actually'): 28,\n",
       "         ('actually', 'a'): 7,\n",
       "         ('a', 'pretty'): 7,\n",
       "         ('pretty', 'reasonable'): 2,\n",
       "         ('reasonable', 'system'): 1,\n",
       "         ('system', 'and'): 36,\n",
       "         ('and', 'i'): 119,\n",
       "         ('think', 'actually'): 1,\n",
       "         ('actually', 'i'): 2,\n",
       "         ('*UNK*', 'give'): 5,\n",
       "         ('give', 'them'): 14,\n",
       "         ('them', 'pretty'): 3,\n",
       "         ('pretty', 'fair'): 2,\n",
       "         ('fair', 'support'): 1,\n",
       "         ('support', 'at'): 2,\n",
       "         ('the', 'moment'): 110,\n",
       "         ('moment', '*end*'): 14,\n",
       "         ('think', 'on'): 2,\n",
       "         ('on', 'average'): 31,\n",
       "         ('average', 'they'): 1,\n",
       "         ('they', 've'): 111,\n",
       "         ('ve', 'performed'): 1,\n",
       "         ('performed', 'fairly'): 1,\n",
       "         ('fairly', 'well'): 2,\n",
       "         ('well', 'another'): 1,\n",
       "         ('another', 'producer'): 2,\n",
       "         ('the', 'biggest'): 89,\n",
       "         ('biggest', 'thing'): 3,\n",
       "         ('thing', 'about'): 9,\n",
       "         ('about', 'someone'): 1,\n",
       "         ('someone', 'else'): 10,\n",
       "         ('else', 'taking'): 1,\n",
       "         ('taking', 'over'): 2,\n",
       "         ('over', 'is'): 3,\n",
       "         ('is', 'whether'): 6,\n",
       "         ('whether', 'the'): 71,\n",
       "         ('*UNK*', 'will'): 203,\n",
       "         ('will', 'get'): 18,\n",
       "         ('get', 'too'): 5,\n",
       "         ('too', 'much'): 38,\n",
       "         ('much', 'of'): 55,\n",
       "         ('of', 'a'): 785,\n",
       "         ('in', 'there'): 18,\n",
       "         ('there', 'and'): 50,\n",
       "         ('and', 'take'): 9,\n",
       "         ('take', 'it'): 11,\n",
       "         ('it', 'too'): 4,\n",
       "         ('much', 'to'): 7,\n",
       "         ('to', 'their'): 89,\n",
       "         ('their', 'advantage'): 2,\n",
       "         ('advantage', '*end*'): 6,\n",
       "         ('*start*', 'grain'): 38,\n",
       "         ('grain', 'prices'): 30,\n",
       "         ('prices', 'but'): 5,\n",
       "         ('but', 'an'): 7,\n",
       "         ('an', 'analyst'): 1,\n",
       "         ('analyst', 'predicts'): 2,\n",
       "         ('predicts', 'grain'): 1,\n",
       "         ('prices', 'will'): 13,\n",
       "         ('will', 'drop'): 7,\n",
       "         ('drop', 'another'): 1,\n",
       "         ('another', '20'): 1,\n",
       "         ('20', 'a'): 3,\n",
       "         ('a', 'tonne'): 49,\n",
       "         ('tonne', 'on'): 3,\n",
       "         ('on', 'the'): 1263,\n",
       "         ('the', 'back'): 38,\n",
       "         ('back', 'of'): 27,\n",
       "         ('into', 'awb'): 9,\n",
       "         ('awb', '*end*'): 23,\n",
       "         ('*start*', 'malcolm'): 5,\n",
       "         ('malcolm', '*UNK*'): 15,\n",
       "         ('*UNK*', 'says'): 2341,\n",
       "         ('says', 'pool'): 1,\n",
       "         ('pool', 'returns'): 9,\n",
       "         ('returns', 'have'): 1,\n",
       "         ('have', 'already'): 36,\n",
       "         ('already', 'dropped'): 1,\n",
       "         ('dropped', 'by'): 4,\n",
       "         ('by', '20'): 12,\n",
       "         ('tonne', 'this'): 2,\n",
       "         ('this', 'year'): 281,\n",
       "         ('year', 'from'): 5,\n",
       "         ('from', 'the'): 1355,\n",
       "         ('the', 'average'): 32,\n",
       "         ('average', 'price'): 9,\n",
       "         ('price', 'over'): 2,\n",
       "         ('over', 'the'): 378,\n",
       "         ('the', 'past'): 228,\n",
       "         ('past', 'five'): 11,\n",
       "         ('five', 'years'): 79,\n",
       "         ('years', '*end*'): 207,\n",
       "         ('that', 'awb'): 15,\n",
       "         ('*UNK*', 'through'): 80,\n",
       "         ('through', 'its'): 5,\n",
       "         ('its', 'wheat'): 7,\n",
       "         ('wheat', 'export'): 60,\n",
       "         ('export', 'monopoly'): 5,\n",
       "         ('monopoly', 'have'): 1,\n",
       "         ('been', 'severely'): 2,\n",
       "         ('severely', 'eroded'): 1,\n",
       "         ('eroded', '*end*'): 1,\n",
       "         ('*start*', 'sa'): 16,\n",
       "         ('sa', 'farmers'): 3,\n",
       "         ('farmers', 'help'): 1,\n",
       "         ('help', 'fire'): 2,\n",
       "         ('fire', '*UNK*'): 17,\n",
       "         ('*UNK*', 'neighbours'): 2,\n",
       "         ('neighbours', 'farmers'): 1,\n",
       "         ('farmers', 'in'): 81,\n",
       "         ('in', 'south'): 157,\n",
       "         ('south', 'australia'): 212,\n",
       "         ('*UNK*', 'south'): 68,\n",
       "         ('south', 'east'): 77,\n",
       "         ('east', 'are'): 4,\n",
       "         ('are', '*UNK*'): 525,\n",
       "         ('of', 'hay'): 8,\n",
       "         ('hay', 'to'): 2,\n",
       "         ('their', 'neighbours'): 4,\n",
       "         ('neighbours', 'across'): 1,\n",
       "         ('across', 'the'): 138,\n",
       "         ('the', 'border'): 13,\n",
       "         ('border', 'in'): 1,\n",
       "         ('in', 'the'): 3913,\n",
       "         ('the', 'wake'): 42,\n",
       "         ('wake', 'of'): 42,\n",
       "         ('*UNK*', 'bushfires'): 3,\n",
       "         ('bushfires', '*end*'): 8,\n",
       "         ('in', 'just'): 14,\n",
       "         ('just', 'a'): 58,\n",
       "         ('a', 'few'): 133,\n",
       "         ('few', 'days'): 14,\n",
       "         ('days', 'farmers'): 1,\n",
       "         ('farmers', 'have'): 65,\n",
       "         ('have', 'donated'): 3,\n",
       "         ('donated', '250'): 1,\n",
       "         ('250', 'tonnes'): 1,\n",
       "         ('tonnes', 'of'): 111,\n",
       "         ('hay', 'as'): 1,\n",
       "         ('as', 'well'): 205,\n",
       "         ('well', 'as'): 115,\n",
       "         ('as', '*UNK*'): 351,\n",
       "         ('*UNK*', 'for'): 715,\n",
       "         ('for', 'cattle'): 11,\n",
       "         ('cattle', '*end*'): 21,\n",
       "         ('*start*', 'they'): 610,\n",
       "         ('they', 'say'): 103,\n",
       "         ('say', 'that'): 57,\n",
       "         ('that', 'is'): 276,\n",
       "         ('is', 'just'): 57,\n",
       "         ('just', 'the'): 21,\n",
       "         ('the', 'beginning'): 18,\n",
       "         ('beginning', '*end*'): 3,\n",
       "         ('*start*', 'fodder'): 4,\n",
       "         ('fodder', 'drive'): 1,\n",
       "         ('drive', 'coordinator'): 1,\n",
       "         ('coordinator', 'peter'): 1,\n",
       "         ('says', 'he'): 241,\n",
       "         ('he', 'has'): 78,\n",
       "         ('the', 'response'): 12,\n",
       "         ('response', '*end*'): 17,\n",
       "         ('*start*', 'all'): 65,\n",
       "         ('all', 'the'): 142,\n",
       "         ('the', 'hay'): 6,\n",
       "         ('hay', 'that'): 1,\n",
       "         ('*UNK*', 'going'): 86,\n",
       "         ('going', 'this'): 1,\n",
       "         ('this', 'week'): 227,\n",
       "         ('week', 'has'): 9,\n",
       "         ('has', 'all'): 4,\n",
       "         ('all', 'gone'): 1,\n",
       "         ('gone', 'from'): 4,\n",
       "         ('from', 'places'): 3,\n",
       "         ('places', 'that'): 6,\n",
       "         ('that', 'have'): 98,\n",
       "         ('donated', 'one'): 1,\n",
       "         ('one', 'load'): 1,\n",
       "         ('load', 'or'): 1,\n",
       "         ('or', 'up'): 1,\n",
       "         ('up', 'to'): 351,\n",
       "         ('two', 'loads'): 1,\n",
       "         ('loads', 'of'): 5,\n",
       "         ('hay', 'he'): 1,\n",
       "         ('*start*', 'we'): 936,\n",
       "         ('we', 've'): 323,\n",
       "         ('ve', 'got'): 137,\n",
       "         ('got', 'one'): 5,\n",
       "         ('one', 'man'): 3,\n",
       "         ('man', 'that'): 1,\n",
       "         ('*UNK*', 'donated'): 1,\n",
       "         ('donated', 'two'): 1,\n",
       "         ('two', 'full'): 1,\n",
       "         ('full', 'loads'): 1,\n",
       "         ('loads', 'and'): 2,\n",
       "         ('the', 'rest'): 42,\n",
       "         ('rest', 'are'): 1,\n",
       "         ('are', 'all'): 13,\n",
       "         ('all', 'one'): 1,\n",
       "         ('one', 'loads'): 1,\n",
       "         ('loads', 'straight'): 1,\n",
       "         ('straight', 'loads'): 1,\n",
       "         ('loads', 'that'): 1,\n",
       "         ('that', 'we'): 306,\n",
       "         ('we', 're'): 338,\n",
       "         ('re', 'moving'): 2,\n",
       "         ('moving', 'this'): 1,\n",
       "         ('week', '*end*'): 127,\n",
       "         ('*start*', '*UNK*'): 2433,\n",
       "         ('*UNK*', 'close'): 15,\n",
       "         ('close', 'highway'): 1,\n",
       "         ('highway', 'a'): 1,\n",
       "         ('a', 'major'): 128,\n",
       "         ('major', 'highway'): 2,\n",
       "         ('highway', 'between'): 2,\n",
       "         ('between', 'the'): 111,\n",
       "         ('the', 'northern'): 176,\n",
       "         ('northern', 'territory'): 132,\n",
       "         ('territory', 'and'): 6,\n",
       "         ('and', 'western'): 20,\n",
       "         ('western', 'australia'): 233,\n",
       "         ('australia', 'remains'): 2,\n",
       "         ('remains', '*UNK*'): 10,\n",
       "         ('by', '*UNK*'): 392,\n",
       "         ('*UNK*', 'today'): 27,\n",
       "         ('today', '*end*'): 95,\n",
       "         ('the', 'victoria'): 9,\n",
       "         ('victoria', 'river'): 5,\n",
       "         ('river', 'has'): 7,\n",
       "         ('has', 'cut'): 10,\n",
       "         ('cut', 'the'): 18,\n",
       "         ('victoria', 'highway'): 2,\n",
       "         ('highway', 'and'): 1,\n",
       "         ('and', 'also'): 35,\n",
       "         ('also', 'flooded'): 1,\n",
       "         ('flooded', 'the'): 2,\n",
       "         ('the', 'remote'): 11,\n",
       "         ('remote', '*UNK*'): 9,\n",
       "         ('*UNK*', 'hole'): 4,\n",
       "         ('hole', 'aboriginal'): 1,\n",
       "         ('aboriginal', 'community'): 9,\n",
       "         ('community', '*end*'): 23,\n",
       "         ('*UNK*', 'simon'): 3,\n",
       "         ('simon', '*UNK*'): 16,\n",
       "         ('*UNK*', 'describes'): 12,\n",
       "         ('describes', 'the'): 18,\n",
       "         ('a', 'hundred'): 13,\n",
       "         ('hundred', 'people'): 4,\n",
       "         ('people', 'to'): 61,\n",
       "         ('to', 'higher'): 8,\n",
       "         ('higher', 'ground'): 2,\n",
       "         ('ground', '*end*'): 24,\n",
       "         ('they', 'had'): 65,\n",
       "         ('had', 'all'): 4,\n",
       "         ('all', 'their'): 5,\n",
       "         ('their', 'vehicles'): 4,\n",
       "         ('vehicles', 'moved'): 1,\n",
       "         ('moved', 'out'): 2,\n",
       "         ('out', 'of'): 270,\n",
       "         ('the', 'community'): 48,\n",
       "         ('community', 'and'): 6,\n",
       "         ('and', 'they'): 160,\n",
       "         ('had', 'a'): 128,\n",
       "         ('few', '*UNK*'): 23,\n",
       "         ('*UNK*', 'set'): 16,\n",
       "         ('set', 'up'): 74,\n",
       "         ('up', 'and'): 63,\n",
       "         ('they', 'were'): 156,\n",
       "         ('were', 'moving'): 2,\n",
       "         ('moving', 'more'): 1,\n",
       "         ('more', 'people'): 15,\n",
       "         ('people', 'and'): 40,\n",
       "         ('and', '*UNK*'): 2294,\n",
       "         ('*UNK*', 'out'): 207,\n",
       "         ('out', 'with'): 23,\n",
       "         ('with', 'a'): 425,\n",
       "         ('a', 'couple'): 46,\n",
       "         ('couple', 'of'): 61,\n",
       "         ('of', 'boats'): 2,\n",
       "         ('boats', 'just'): 1,\n",
       "         ('just', 'onto'): 1,\n",
       "         ('onto', 'higher'): 1,\n",
       "         ('ground', 'only'): 1,\n",
       "         ('only', '500'): 1,\n",
       "         ('500', 'metres'): 4,\n",
       "         ('metres', 'from'): 2,\n",
       "         ('community', 'he'): 5,\n",
       "         ('they', 'are'): 419,\n",
       "         ('are', 'up'): 18,\n",
       "         ('up', 'on'): 31,\n",
       "         ('on', 'a'): 265,\n",
       "         ('moment', 'and'): 10,\n",
       "         ('think', 'the'): 84,\n",
       "         ('the', 'river'): 45,\n",
       "         ('river', '*UNK*'): 21,\n",
       "         ('*UNK*', 'might'): 33,\n",
       "         ('might', 'be'): 101,\n",
       "         ('be', 'up'): 12,\n",
       "         ('up', 'for'): 35,\n",
       "         ('for', 'a'): 352,\n",
       "         ('a', 'little'): 89,\n",
       "         ('little', 'longer'): 2,\n",
       "         ('longer', 'but'): 1,\n",
       "         ('but', 'i'): 54,\n",
       "         ('it', 'the'): 22,\n",
       "         ('river', 'will'): 6,\n",
       "         ('will', 'start'): 21,\n",
       "         ('start', 'going'): 2,\n",
       "         ('going', 'down'): 3,\n",
       "         ('down', '*end*'): 30,\n",
       "         ('grain', 'company'): 2,\n",
       "         ('company', 'sold'): 1,\n",
       "         ('sold', 'for'): 19,\n",
       "         ('for', '*UNK*'): 506,\n",
       "         ('*UNK*', 'tasmania'): 7,\n",
       "         ('tasmania', '*UNK*'): 53,\n",
       "         ('*UNK*', 'main'): 12,\n",
       "         ('main', 'grain'): 3,\n",
       "         ('company', 'has'): 38,\n",
       "         ('has', 'changed'): 7,\n",
       "         ('changed', 'hands'): 2,\n",
       "         ('hands', 'for'): 1,\n",
       "         ('for', 'the'): 1015,\n",
       "         ('the', 'second'): 71,\n",
       "         ('second', 'time'): 4,\n",
       "         ('time', 'in'): 56,\n",
       "         ('just', 'three'): 7,\n",
       "         ('three', 'years'): 72,\n",
       "         ('the', 'former'): 20,\n",
       "         ('former', 'state'): 1,\n",
       "         ('state', 'owned'): 2,\n",
       "         ('owned', 'tasmanian'): 1,\n",
       "         ('tasmanian', 'grain'): 3,\n",
       "         ('grain', '*UNK*'): 21,\n",
       "         ('*UNK*', 'board'): 9,\n",
       "         ('board', 'has'): 5,\n",
       "         ('been', 'sold'): 10,\n",
       "         ('sold', 'to'): 13,\n",
       "         ('to', 'local'): 10,\n",
       "         ('local', 'agribusiness'): 1,\n",
       "         ('agribusiness', 'roberts'): 2,\n",
       "         ('roberts', 'limited'): 6,\n",
       "         ('limited', 'for'): 2,\n",
       "         ('for', 'about'): 21,\n",
       "         ('about', '*UNK*'): 193,\n",
       "         ('the', 'deal'): 28,\n",
       "         ('deal', 'includes'): 1,\n",
       "         ('includes', 'silos'): 1,\n",
       "         ('silos', 'at'): 1,\n",
       "         ('at', '*UNK*'): 442,\n",
       "         ('*UNK*', 'and'): 3154,\n",
       "         ('in', 'northern'): 42,\n",
       "         ('northern', 'tasmania'): 10,\n",
       "         ('tasmania', '*end*'): 21,\n",
       "         ('*start*', 'john'): 34,\n",
       "         ('john', '*UNK*'): 118,\n",
       "         ('*UNK*', 'from'): 1031,\n",
       "         ('from', 'roberts'): 3,\n",
       "         ('limited', 'says'): 7,\n",
       "         ('the', 'company'): 223,\n",
       "         ('company', 'bid'): 1,\n",
       "         ('bid', 'when'): 1,\n",
       "         ('when', 'the'): 175,\n",
       "         ('the', 'board'): 20,\n",
       "         ('board', 'was'): 2,\n",
       "         ('was', 'first'): 16,\n",
       "         ('first', '*UNK*'): 66,\n",
       "         ('*UNK*', '*end*'): 4401,\n",
       "         ('we', 'were'): 60,\n",
       "         ('were', 'very'): 14,\n",
       "         ('very', 'disappointed'): 4,\n",
       "         ('disappointed', 'we'): 1,\n",
       "         ('we', 'weren'): 9,\n",
       "         ('weren', '*UNK*'): 25,\n",
       "         ('*UNK*', 'successful'): 3,\n",
       "         ('successful', 'at'): 1,\n",
       "         ('at', 'that'): 21,\n",
       "         ('that', 'point'): 5,\n",
       "         ('point', 'of'): 21,\n",
       "         ('of', 'time'): 36,\n",
       "         ('time', 'he'): 14,\n",
       "         ('*start*', 'wine'): 18,\n",
       "         ('wine', 'workers'): 1,\n",
       "         ('workers', 'stop'): 1,\n",
       "         ('stop', 'work'): 1,\n",
       "         ('work', 'workers'): 1,\n",
       "         ('workers', 'at'): 13,\n",
       "         ('*UNK*', 'wines'): 11,\n",
       "         ('wines', 'stanley'): 1,\n",
       "         ('stanley', '*UNK*'): 3,\n",
       "         ('south', 'western'): 2,\n",
       "         ('wales', 'have'): 18,\n",
       "         ('have', 'walked'): 1,\n",
       "         ('walked', 'off'): 3,\n",
       "         ('off', 'the'): 94,\n",
       "         ('the', 'job'): 20,\n",
       "         ('job', 'for'): 4,\n",
       "         ('in', 'a'): 737,\n",
       "         ('a', 'week'): 29,\n",
       "         ('*UNK*', 'staff'): 10,\n",
       "         ('staff', 'walked'): 1,\n",
       "         ('walked', 'out'): 2,\n",
       "         ('out', 'this'): 6,\n",
       "         ('this', 'morning'): 35,\n",
       "         ('morning', 'in'): 4,\n",
       "         ('a', 'dispute'): 8,\n",
       "         ('dispute', 'over'): 7,\n",
       "         ('over', 'a'): 62,\n",
       "         ('a', 'new'): 471,\n",
       "         ('new', '*UNK*'): 141,\n",
       "         ('*UNK*', 'bargaining'): 5,\n",
       "         ('bargaining', 'agreement'): 2,\n",
       "         ('agreement', '*end*'): 12,\n",
       "         ('*UNK*', 'comes'): 15,\n",
       "         ('comes', 'just'): 4,\n",
       "         ('just', 'as'): 34,\n",
       "         ('as', 'the'): 332,\n",
       "         ('the', 'region'): 96,\n",
       "         ('region', '*UNK*'): 19,\n",
       "         ('*UNK*', 'wine'): 16,\n",
       "         ('wine', 'grape'): 22,\n",
       "         ('grape', 'crush'): 2,\n",
       "         ('crush', 'gets'): 1,\n",
       "         ('gets', 'under'): 1,\n",
       "         ('under', 'way'): 60,\n",
       "         ('way', '*end*'): 42,\n",
       "         ('wines', 'took'): 1,\n",
       "         ('took', 'the'): 13,\n",
       "         ('the', 'matter'): 11,\n",
       "         ('matter', 'to'): 3,\n",
       "         ('the', 'industrial'): 6,\n",
       "         ('industrial', 'relations'): 6,\n",
       "         ('relations', 'commission'): 1,\n",
       "         ('commission', '*UNK*'): 21,\n",
       "         ('*UNK*', 'on'): 593,\n",
       "         ('on', 'friday'): 19,\n",
       "         ('friday', '*end*'): 8,\n",
       "         ('*start*', 'wool'): 41,\n",
       "         ('wool', 'body'): 2,\n",
       "         ('body', 'eyes'): 1,\n",
       "         ('eyes', '*UNK*'): 3,\n",
       "         ('*UNK*', 'industry'): 57,\n",
       "         ('industry', 'the'): 18,\n",
       "         ('the', '50'): 5,\n",
       "         ('50', 'billion'): 3,\n",
       "         ('billion', 'global'): 1,\n",
       "         ('global', '*UNK*'): 14,\n",
       "         ('industry', 'is'): 89,\n",
       "         ('is', 'the'): 474,\n",
       "         ('the', 'new'): 401,\n",
       "         ('new', 'target'): 1,\n",
       "         ('target', 'of'): 6,\n",
       "         ('of', 'wool'): 28,\n",
       "         ('wool', 'promotion'): 1,\n",
       "         ('promotion', 'body'): 1,\n",
       "         ('body', 'australian'): 5,\n",
       "         ('australian', 'wool'): 73,\n",
       "         ('wool', 'innovation'): 37,\n",
       "         ('innovation', 'awi'): 17,\n",
       "         ('awi', '*end*'): 8,\n",
       "         ('*start*', 'awi'): 14,\n",
       "         ('awi', 'is'): 2,\n",
       "         ('is', 'showing'): 7,\n",
       "         ('showing', 'wool'): 1,\n",
       "         ('wool', 'blend'): 2,\n",
       "         ('blend', '*UNK*'): 3,\n",
       "         ('*UNK*', 'wear'): 2,\n",
       "         ('wear', 'to'): 1,\n",
       "         ('to', 'manufacturers'): 2,\n",
       "         ('manufacturers', 'this'): 1,\n",
       "         ('week', 'at'): 22,\n",
       "         ('the', 'largest'): 57,\n",
       "         ('largest', 'trade'): 1,\n",
       "         ('trade', 'show'): 1,\n",
       "         ('show', 'for'): 3,\n",
       "         ('the', 'industry'): 201,\n",
       "         ('industry', 'being'): 2,\n",
       "         ('being', 'held'): 8,\n",
       "         ('held', 'in'): 20,\n",
       "         ('in', 'germany'): 12,\n",
       "         ('germany', '*end*'): 8,\n",
       "         ('awi', '*UNK*'): 7,\n",
       "         ('*UNK*', 'stephens'): 8,\n",
       "         ('stephens', 'says'): 6,\n",
       "         ('says', 'although'): 19,\n",
       "         ('although', 'wool'): 1,\n",
       "         ('will', 'be'): 733,\n",
       "         ('be', 'at'): 25,\n",
       "         ('*UNK*', 'end'): 13,\n",
       "         ('end', 'of'): 134,\n",
       "         ('the', 'market'): 137,\n",
       "         ('market', 'shoppers'): 1,\n",
       "         ('shoppers', 'are'): 2,\n",
       "         ('are', 'willing'): 5,\n",
       "         ('willing', 'to'): 21,\n",
       "         ('to', 'pay'): 72,\n",
       "         ('pay', 'more'): 18,\n",
       "         ('more', '*end*'): 29,\n",
       "         ('the', 'sports'): 2,\n",
       "         ('sports', '*UNK*'): 7,\n",
       "         ('*UNK*', 'market'): 23,\n",
       "         ('market', 'sector'): 1,\n",
       "         ('sector', 'is'): 12,\n",
       "         ('is', 'one'): 77,\n",
       "         ('biggest', 'and'): 6,\n",
       "         ('and', 'certainly'): 5,\n",
       "         ('certainly', 'the'): 10,\n",
       "         ('*UNK*', 'growing'): 12,\n",
       "         ('growing', '*UNK*'): 10,\n",
       "         ('*UNK*', 'sector'): 5,\n",
       "         ('sector', 'in'): 6,\n",
       "         ('the', 'world'): 394,\n",
       "         ('world', 'and'): 17,\n",
       "         ('and', 'it'): 194,\n",
       "         ('*UNK*', 'no'): 85,\n",
       "         ('no', 'secret'): 1,\n",
       "         ('secret', 'that'): 1,\n",
       "         ('that', 'wool'): 4,\n",
       "         ('wool', 'hasn'): 1,\n",
       "         ('hasn', '*UNK*'): 44,\n",
       "         ('*UNK*', 'had'): 93,\n",
       "         ('a', 'very'): 170,\n",
       "         ('very', 'big'): 6,\n",
       "         ('big', 'share'): 1,\n",
       "         ('share', 'of'): 15,\n",
       "         ('of', 'that'): 66,\n",
       "         ('that', 'market'): 9,\n",
       "         ('market', 'at'): 2,\n",
       "         ('at', 'all'): 69,\n",
       "         ('all', 'he'): 11,\n",
       "         ('the', 'level'): 27,\n",
       "         ('level', 'of'): 58,\n",
       "         ('wool', 'particularly'): 1,\n",
       "         ('particularly', 'australian'): 1,\n",
       "         ('australian', 'merino'): 1,\n",
       "         ('merino', 'wool'): 3,\n",
       "         ('wool', 'in'): 11,\n",
       "         ('sports', 'market'): 1,\n",
       "         ('market', 'is'): 22,\n",
       "         ('is', 'really'): 33,\n",
       "         ('really', 'almost'): 1,\n",
       "         ('almost', 'below'): 1,\n",
       "         ('below', 'the'): 27,\n",
       "         ('the', 'radar'): 3,\n",
       "         ('radar', '*end*'): 3,\n",
       "         ('*start*', 'organisation'): 1,\n",
       "         ('organisation', 'to'): 4,\n",
       "         ('to', 'step'): 11,\n",
       "         ('step', 'up'): 10,\n",
       "         ('up', '*UNK*'): 67,\n",
       "         ('*UNK*', 'campaign'): 6,\n",
       "         ('campaign', 'tasmania'): 1,\n",
       "         ('*UNK*', 'rodeo'): 4,\n",
       "         ('rodeo', 'industry'): 1,\n",
       "         ('is', 'under'): 37,\n",
       "         ('under', '*UNK*'): 15,\n",
       "         ('*UNK*', 'attack'): 4,\n",
       "         ('attack', 'from'): 2,\n",
       "         ('from', 'animal'): 4,\n",
       "         ('animal', 'rights'): 24,\n",
       "         ('rights', 'activists'): 4,\n",
       "         ('activists', 'after'): 1,\n",
       "         ('after', 'another'): 4,\n",
       "         ('another', 'animal'): 1,\n",
       "         ('animal', 'had'): 2,\n",
       "         ('had', 'to'): 73,\n",
       "         ('be', 'destroyed'): 8,\n",
       "         ('destroyed', 'at'): 3,\n",
       "         ('at', 'a'): 244,\n",
       "         ('a', 'weekend'): 7,\n",
       "         ('weekend', 'event'): 1,\n",
       "         ('event', '*end*'): 18,\n",
       "         ('*start*', 'a'): 524,\n",
       "         ('*UNK*', 'horse'): 9,\n",
       "         ('horse', 'was'): 2,\n",
       "         ('was', 'put'): 7,\n",
       "         ('put', 'down'): 6,\n",
       "         ('down', 'after'): 4,\n",
       "         ('after', 'breaking'): 2,\n",
       "         ('breaking', 'a'): 1,\n",
       "         ('a', 'leg'): 4,\n",
       "         ('leg', 'at'): 2,\n",
       "         ('on', 'saturday'): 11,\n",
       "         ('saturday', '*end*'): 5,\n",
       "         ('*start*', 'two'): 48,\n",
       "         ('two', 'weeks'): 35,\n",
       "         ('weeks', 'ago'): 22,\n",
       "         ('ago', 'a'): 8,\n",
       "         ('a', 'bull'): 6,\n",
       "         ('bull', 'was'): 3,\n",
       "         ('was', 'destroyed'): 2,\n",
       "         ('destroyed', 'after'): 2,\n",
       "         ('after', 'apparently'): 1,\n",
       "         ('apparently', 'breaking'): 1,\n",
       "         ('breaking', 'its'): 2,\n",
       "         ('its', 'back'): 5,\n",
       "         ('back', 'during'): 1,\n",
       "         ('during', 'a'): 35,\n",
       "         ('bull', 'riding'): 1,\n",
       "         ('riding', 'competition'): 1,\n",
       "         ('competition', 'at'): 6,\n",
       "         ('the', 'owner'): 10,\n",
       "         ('owner', 'of'): 7,\n",
       "         ('of', 'both'): 22,\n",
       "         ('both', 'animals'): 1,\n",
       "         ('animals', 'brian'): 1,\n",
       "         ('brian', 'fish'): 1,\n",
       "         ('fish', 'says'): 5,\n",
       "         ('says', 'they'): 72,\n",
       "         ('were', '*UNK*'): 171,\n",
       "         ('and', 'not'): 64,\n",
       "         ('not', 'an'): 17,\n",
       "         ('an', 'animal'): 23,\n",
       "         ('animal', 'welfare'): 33,\n",
       "         ('welfare', 'issue'): 1,\n",
       "         ('issue', '*end*'): 23,\n",
       "         ('but', '*UNK*'): 200,\n",
       "         ('from', 'against'): 1,\n",
       "         ('against', 'animal'): 3,\n",
       "         ('animal', 'cruelty'): 10,\n",
       "         ('cruelty', 'tasmania'): 2,\n",
       "         ('tasmania', 'says'): 8,\n",
       "         ('says', 'her'): 22,\n",
       "         ('her', 'organisation'): 4,\n",
       "         ('organisation', 'will'): 1,\n",
       "         ('will', 'up'): 1,\n",
       "         ('up', 'its'): 12,\n",
       "         ('its', 'efforts'): 4,\n",
       "         ('efforts', 'to'): 22,\n",
       "         ('to', 'have'): 360,\n",
       "         ('*UNK*', 'banned'): 3,\n",
       "         ('banned', '*end*'): 3,\n",
       "         ('*start*', 'snails'): 1,\n",
       "         ('snails', 'used'): 1,\n",
       "         ('used', 'in'): 99,\n",
       "         ('in', 'cancer'): 6,\n",
       "         ('cancer', 'research'): 5,\n",
       "         ('research', 'new'): 5,\n",
       "         ('new', 'research'): 80,\n",
       "         ('research', 'is'): 44,\n",
       "         ('way', 'to'): 97,\n",
       "         ('to', 'investigate'): 40,\n",
       "         ('investigate', 'whether'): 5,\n",
       "         ('whether', 'south'): 1,\n",
       "         ('south', 'australian'): 76,\n",
       "         ('australian', 'sea'): 1,\n",
       "         ('sea', 'snails'): 2,\n",
       "         ('snails', 'could'): 2,\n",
       "         ('could', 'eventually'): 10,\n",
       "         ('eventually', 'be'): 3,\n",
       "         ('be', 'used'): 179,\n",
       "         ('used', 'to'): 242,\n",
       "         ('to', 'treat'): 32,\n",
       "         ('treat', 'cancer'): 3,\n",
       "         ('cancer', '*end*'): 30,\n",
       "         ('*start*', 'until'): 34,\n",
       "         ('until', 'now'): 43,\n",
       "         ('now', 'the'): 33,\n",
       "         ('the', 'state'): 283,\n",
       "         ('state', '*UNK*'): 139,\n",
       "         ('*UNK*', 'snail'): 2,\n",
       "         ('snail', 'population'): 1,\n",
       "         ('population', 'has'): 3,\n",
       "         ('been', 'virtually'): 2,\n",
       "         ('virtually', '*UNK*'): 10,\n",
       "         ('*UNK*', 'but'): 252,\n",
       "         ('but', 'flinders'): 1,\n",
       "         ('flinders', 'university'): 10,\n",
       "         ('university', 'hopes'): 1,\n",
       "         ...})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_model.bigram_voc_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything that was presented can also be done for a trigram model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proving that the models works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sents, test_set, _, _ = train_test_split(sentences, sentences, test_size=0.2, random_state=42)  # keep test set \n",
    "train_set, dev_set, _, _ = train_test_split(train_sents, train_sents, test_size=0.1, random_state=42)  # split the train set to dev and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_model = LM(n_type='bigram')\n",
    "bi_model.train(train_set)\n",
    "\n",
    "tri_model = LM(n_type='trigram')\n",
    "tri_model.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Entropy and Perplexity using the Bigram Model with Add-a Smoothing: 6.780454239756531 and 109.93098273596117\n",
      "Cross-Entropy and Perplexity using the Bigram Model with K-N Smoothing: 6.427927593043861 and 86.09918003297753\n",
      "Cross-Entropy and Perplexity using the Trigram Model with Add-a Smoothing: 8.560095402262942 and 377.43787794141315\n"
     ]
    }
   ],
   "source": [
    "lap_hc, lap_pp = bi_model.entr_perp(test_set, a=0.01)\n",
    "kn_hc, kn_pp = bi_model.entr_perp(test_set, smoothing='kn')\n",
    "tri_hc, tri_pp = tri_model.entr_perp(test_set, a=0.007)\n",
    "\n",
    "print(f\"Cross-Entropy and Perplexity using the Bigram Model with Add-a Smoothing: {lap_hc} and {lap_pp}\")\n",
    "print(f\"Cross-Entropy and Perplexity using the Bigram Model with K-N Smoothing: {kn_hc} and {kn_pp}\")\n",
    "print(f\"Cross-Entropy and Perplexity using the Trigram Model with Add-a Smoothing: {tri_hc} and {tri_pp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "test_shfl = test_set[:]\n",
    "foo = [shuffle(sent) for sent in test_shfl]  # shuffle the order of words from each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Entropy and Perplexity using the Bigram Model with Add-a Smoothing on shuffled sentences: 9.356070591143954 and 655.3267402755667\n",
      "Cross-Entropy and Perplexity using the Bigram Model with K-N Smoothing on shuffled sentences: 8.231113955160426 and 300.4776667419467\n",
      "Cross-Entropy and Perplexity using the Trigram Model with Add-a Smoothing on shuffled sentences: 10.727254898805462 and 1695.2177679941951\n"
     ]
    }
   ],
   "source": [
    "lap_hc, lap_pp = bi_model.entr_perp(test_shfl, a=0.01)\n",
    "kn_hc, kn_pp = bi_model.entr_perp(test_shfl, smoothing='kn')\n",
    "tri_hc, tri_pp = tri_model.entr_perp(test_shfl, a=0.007)\n",
    "\n",
    "print(f\"Cross-Entropy and Perplexity using the Bigram Model with Add-a Smoothing on shuffled sentences: {lap_hc} and {lap_pp}\")\n",
    "print(f\"Cross-Entropy and Perplexity using the Bigram Model with K-N Smoothing on shuffled sentences: {kn_hc} and {kn_pp}\")\n",
    "print(f\"Cross-Entropy and Perplexity using the Trigram Model with Add-a Smoothing on shuffled sentences: {tri_hc} and {tri_pp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models seems to assign lower probabilities (higher cross-entropy and perplexity) to ‘non-sense’ sentences, which means that the models are working!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the most probable next word using the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def next_word(word, model, smoother='kn', a=1):  # This function will return the top 10 most probable word continuations\n",
    "    voc = list(model.unigram_voc_.keys())\n",
    "    voc.remove('*start*')\n",
    "    voc.remove('*UNK*')\n",
    "    voc.remove('*end*')\n",
    "    \n",
    "    if smoother == 'kn':\n",
    "        next_word = {key: bi_model.kn_prob((word, key)) for key in voc}\n",
    "    else:\n",
    "        next_word = {key: bi_model.estimate_ngram_prob((word, key), a=a) for key in voc}\n",
    "\n",
    "    sorted_words = dict(sorted(next_word.items(), key=lambda item: item[1]))\n",
    "    top10 = {i: sorted_words[i] for i in list(sorted_words.keys())[-10:]}\n",
    "\n",
    "    return pd.DataFrame(top10.items()).rename(columns = {0: word, 1: 'Probability'}).sort_values(by='Probability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>he</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>said</td>\n",
       "      <td>0.393450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>says</td>\n",
       "      <td>0.334239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>is</td>\n",
       "      <td>0.042016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>has</td>\n",
       "      <td>0.019871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>was</td>\n",
       "      <td>0.014306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>will</td>\n",
       "      <td>0.012982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>had</td>\n",
       "      <td>0.008395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>0.007996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>also</td>\n",
       "      <td>0.007358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adds</td>\n",
       "      <td>0.007307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     he  Probability\n",
       "9  said     0.393450\n",
       "8  says     0.334239\n",
       "7    is     0.042016\n",
       "6   has     0.019871\n",
       "5   was     0.014306\n",
       "4  will     0.012982\n",
       "3   had     0.008395\n",
       "2   and     0.007996\n",
       "1  also     0.007358\n",
       "0  adds     0.007307"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_word('he', bi_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>good</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>news</td>\n",
       "      <td>0.097392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>for</td>\n",
       "      <td>0.032394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>at</td>\n",
       "      <td>0.027989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>to</td>\n",
       "      <td>0.027153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>and</td>\n",
       "      <td>0.024799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>as</td>\n",
       "      <td>0.017111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prices</td>\n",
       "      <td>0.015528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enough</td>\n",
       "      <td>0.015374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thing</td>\n",
       "      <td>0.015267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>on</td>\n",
       "      <td>0.013858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     good  Probability\n",
       "9    news     0.097392\n",
       "8     for     0.032394\n",
       "7      at     0.027989\n",
       "6      to     0.027153\n",
       "5     and     0.024799\n",
       "4      as     0.017111\n",
       "3  prices     0.015528\n",
       "2  enough     0.015374\n",
       "1   thing     0.015267\n",
       "0      on     0.013858"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_word('good', bi_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a</td>\n",
       "      <td>0.126892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the</td>\n",
       "      <td>0.121113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>it</td>\n",
       "      <td>0.114721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sure</td>\n",
       "      <td>0.077509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>up</td>\n",
       "      <td>0.046269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>them</td>\n",
       "      <td>0.030285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sense</td>\n",
       "      <td>0.016443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>any</td>\n",
       "      <td>0.014327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>an</td>\n",
       "      <td>0.012478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people</td>\n",
       "      <td>0.012267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     make  Probability\n",
       "9       a     0.126892\n",
       "8     the     0.121113\n",
       "7      it     0.114721\n",
       "6    sure     0.077509\n",
       "5      up     0.046269\n",
       "4    them     0.030285\n",
       "3   sense     0.016443\n",
       "2     any     0.014327\n",
       "1      an     0.012478\n",
       "0  people     0.012267"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_word('make', bi_model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d730a2b9894ef36cca77d717dfbf37657b5f05c487fae01f16d101a9a41534c0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
